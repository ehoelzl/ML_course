{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Input, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, BatchNormalization,Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 50\n",
    "IMG_WIDTH, IMG_HEIGHT = 16, 16\n",
    "NUM_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets/training/images/satImage_001.png\n",
      "Loading Datasets/training/images/satImage_002.png\n",
      "Loading Datasets/training/images/satImage_003.png\n",
      "Loading Datasets/training/images/satImage_004.png\n",
      "Loading Datasets/training/images/satImage_005.png\n",
      "Loading Datasets/training/images/satImage_006.png\n",
      "Loading Datasets/training/images/satImage_007.png\n",
      "Loading Datasets/training/images/satImage_008.png\n",
      "Loading Datasets/training/images/satImage_009.png\n",
      "Loading Datasets/training/images/satImage_010.png\n",
      "Loading Datasets/training/images/satImage_011.png\n",
      "Loading Datasets/training/images/satImage_012.png\n",
      "Loading Datasets/training/images/satImage_013.png\n",
      "Loading Datasets/training/images/satImage_014.png\n",
      "Loading Datasets/training/images/satImage_015.png\n",
      "Loading Datasets/training/images/satImage_016.png\n",
      "Loading Datasets/training/images/satImage_017.png\n",
      "Loading Datasets/training/images/satImage_018.png\n",
      "Loading Datasets/training/images/satImage_019.png\n",
      "Loading Datasets/training/images/satImage_020.png\n",
      "Loading Datasets/training/images/satImage_021.png\n",
      "Loading Datasets/training/images/satImage_022.png\n",
      "Loading Datasets/training/images/satImage_023.png\n",
      "Loading Datasets/training/images/satImage_024.png\n",
      "Loading Datasets/training/images/satImage_025.png\n",
      "Loading Datasets/training/images/satImage_026.png\n",
      "Loading Datasets/training/images/satImage_027.png\n",
      "Loading Datasets/training/images/satImage_028.png\n",
      "Loading Datasets/training/images/satImage_029.png\n",
      "Loading Datasets/training/images/satImage_030.png\n",
      "Loading Datasets/training/images/satImage_031.png\n",
      "Loading Datasets/training/images/satImage_032.png\n",
      "Loading Datasets/training/images/satImage_033.png\n",
      "Loading Datasets/training/images/satImage_034.png\n",
      "Loading Datasets/training/images/satImage_035.png\n",
      "Loading Datasets/training/images/satImage_036.png\n",
      "Loading Datasets/training/images/satImage_037.png\n",
      "Loading Datasets/training/images/satImage_038.png\n",
      "Loading Datasets/training/images/satImage_039.png\n",
      "Loading Datasets/training/images/satImage_040.png\n",
      "Loading Datasets/training/images/satImage_041.png\n",
      "Loading Datasets/training/images/satImage_042.png\n",
      "Loading Datasets/training/images/satImage_043.png\n",
      "Loading Datasets/training/images/satImage_044.png\n",
      "Loading Datasets/training/images/satImage_045.png\n",
      "Loading Datasets/training/images/satImage_046.png\n",
      "Loading Datasets/training/images/satImage_047.png\n",
      "Loading Datasets/training/images/satImage_048.png\n",
      "Loading Datasets/training/images/satImage_049.png\n",
      "Loading Datasets/training/images/satImage_050.png\n",
      "Loading Datasets/training/groundtruth/satImage_001.png\n",
      "Loading Datasets/training/groundtruth/satImage_002.png\n",
      "Loading Datasets/training/groundtruth/satImage_003.png\n",
      "Loading Datasets/training/groundtruth/satImage_004.png\n",
      "Loading Datasets/training/groundtruth/satImage_005.png\n",
      "Loading Datasets/training/groundtruth/satImage_006.png\n",
      "Loading Datasets/training/groundtruth/satImage_007.png\n",
      "Loading Datasets/training/groundtruth/satImage_008.png\n",
      "Loading Datasets/training/groundtruth/satImage_009.png\n",
      "Loading Datasets/training/groundtruth/satImage_010.png\n",
      "Loading Datasets/training/groundtruth/satImage_011.png\n",
      "Loading Datasets/training/groundtruth/satImage_012.png\n",
      "Loading Datasets/training/groundtruth/satImage_013.png\n",
      "Loading Datasets/training/groundtruth/satImage_014.png\n",
      "Loading Datasets/training/groundtruth/satImage_015.png\n",
      "Loading Datasets/training/groundtruth/satImage_016.png\n",
      "Loading Datasets/training/groundtruth/satImage_017.png\n",
      "Loading Datasets/training/groundtruth/satImage_018.png\n",
      "Loading Datasets/training/groundtruth/satImage_019.png\n",
      "Loading Datasets/training/groundtruth/satImage_020.png\n",
      "Loading Datasets/training/groundtruth/satImage_021.png\n",
      "Loading Datasets/training/groundtruth/satImage_022.png\n",
      "Loading Datasets/training/groundtruth/satImage_023.png\n",
      "Loading Datasets/training/groundtruth/satImage_024.png\n",
      "Loading Datasets/training/groundtruth/satImage_025.png\n",
      "Loading Datasets/training/groundtruth/satImage_026.png\n",
      "Loading Datasets/training/groundtruth/satImage_027.png\n",
      "Loading Datasets/training/groundtruth/satImage_028.png\n",
      "Loading Datasets/training/groundtruth/satImage_029.png\n",
      "Loading Datasets/training/groundtruth/satImage_030.png\n",
      "Loading Datasets/training/groundtruth/satImage_031.png\n",
      "Loading Datasets/training/groundtruth/satImage_032.png\n",
      "Loading Datasets/training/groundtruth/satImage_033.png\n",
      "Loading Datasets/training/groundtruth/satImage_034.png\n",
      "Loading Datasets/training/groundtruth/satImage_035.png\n",
      "Loading Datasets/training/groundtruth/satImage_036.png\n",
      "Loading Datasets/training/groundtruth/satImage_037.png\n",
      "Loading Datasets/training/groundtruth/satImage_038.png\n",
      "Loading Datasets/training/groundtruth/satImage_039.png\n",
      "Loading Datasets/training/groundtruth/satImage_040.png\n",
      "Loading Datasets/training/groundtruth/satImage_041.png\n",
      "Loading Datasets/training/groundtruth/satImage_042.png\n",
      "Loading Datasets/training/groundtruth/satImage_043.png\n",
      "Loading Datasets/training/groundtruth/satImage_044.png\n",
      "Loading Datasets/training/groundtruth/satImage_045.png\n",
      "Loading Datasets/training/groundtruth/satImage_046.png\n",
      "Loading Datasets/training/groundtruth/satImage_047.png\n",
      "Loading Datasets/training/groundtruth/satImage_048.png\n",
      "Loading Datasets/training/groundtruth/satImage_049.png\n",
      "Loading Datasets/training/groundtruth/satImage_050.png\n",
      "Number of data points per class: c0 = 23384 c1 = 7866\n",
      "Balancing training data...\n",
      "15732\n",
      "(31250, 16, 16, 3)\n",
      "Number of data points per class: c0 = 7866 c1 = 7866\n"
     ]
    }
   ],
   "source": [
    "from tf_aerial_images import extract_data, extract_labels\n",
    "data_dir = 'Datasets/training/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/' \n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, TRAINING_SIZE)\n",
    "train_labels = extract_labels(train_labels_filename, TRAINING_SIZE)\n",
    "\n",
    "c0 = 0  # bgrd\n",
    "c1 = 0  # road\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "\n",
    "print('Balancing training data...')\n",
    "min_c = min(c0, c1)\n",
    "idx0 = [i for i, j in enumerate(train_labels) if j[0] == 1]\n",
    "idx1 = [i for i, j in enumerate(train_labels) if j[1] == 1]\n",
    "new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "print(len(new_indices))\n",
    "print(train_data.shape)\n",
    "train_data = train_data[new_indices, :, :, :]\n",
    "train_labels = train_labels[new_indices]\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "c0 = 0\n",
    "c1 = 0\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS))\n",
    "# Conv 1 3x3 16 units\n",
    "c1 = Conv2D(32, (5, 5), activation='relu', kernel_initializer='truncated_normal', padding='same', use_bias=True) (inputs)\n",
    "p1 = MaxPooling2D((2, 2), strides=2) (c1)\n",
    "\n",
    "c2 = Conv2D(64, (5, 5), activation = 'relu', kernel_initializer='truncated_normal', padding='same', use_bias=True) (p1)\n",
    "p2 = MaxPooling2D((2, 2), strides=2) (c2)\n",
    "\n",
    "f1 = Flatten()(p2)\n",
    "d1 = Dense(512, activation='relu', kernel_initializer='truncated_normal', use_bias=True)(f1)\n",
    "d1 = Dropout(0.5)(d1)\n",
    "outputs = Dense(2, activation='softmax', kernel_initializer='truncated_normal', use_bias=True)(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 16, 16, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 579,522\n",
      "Trainable params: 579,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "adam = optimizers.Adamax(lr=1e-3)\n",
    "model.compile(optimizer=adam, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12585 samples, validate on 3147 samples\n",
      "Epoch 1/100\n",
      "12585/12585 [==============================] - 14s 1ms/sample - loss: 0.4173 - acc: 0.8064 - val_loss: 0.7120 - val_acc: 0.7274\n",
      "Epoch 2/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.4080 - acc: 0.8086 - val_loss: 0.5385 - val_acc: 0.8179\n",
      "Epoch 3/100\n",
      "12585/12585 [==============================] - 14s 1ms/sample - loss: 0.4007 - acc: 0.8157 - val_loss: 0.7697 - val_acc: 0.6880\n",
      "Epoch 4/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.3925 - acc: 0.8178 - val_loss: 0.8591 - val_acc: 0.6336\n",
      "Epoch 5/100\n",
      "12585/12585 [==============================] - 15s 1ms/sample - loss: 0.3821 - acc: 0.8268 - val_loss: 0.9695 - val_acc: 0.5891\n",
      "Epoch 6/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.3810 - acc: 0.8253 - val_loss: 0.6793 - val_acc: 0.7461\n",
      "Epoch 7/100\n",
      "12585/12585 [==============================] - 15s 1ms/sample - loss: 0.3701 - acc: 0.8317 - val_loss: 0.8163 - val_acc: 0.6829\n",
      "Epoch 8/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.3626 - acc: 0.8394 - val_loss: 0.9052 - val_acc: 0.6403\n",
      "Epoch 9/100\n",
      "12585/12585 [==============================] - 15s 1ms/sample - loss: 0.3538 - acc: 0.8439 - val_loss: 1.0060 - val_acc: 0.6063\n",
      "Epoch 10/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.3497 - acc: 0.8462 - val_loss: 0.5587 - val_acc: 0.7982\n",
      "Epoch 11/100\n",
      "12585/12585 [==============================] - 17s 1ms/sample - loss: 0.3413 - acc: 0.8512 - val_loss: 0.7742 - val_acc: 0.7242\n",
      "Epoch 12/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.3367 - acc: 0.8526 - val_loss: 0.6885 - val_acc: 0.7579\n",
      "Epoch 13/100\n",
      "12585/12585 [==============================] - 21s 2ms/sample - loss: 0.3229 - acc: 0.8613 - val_loss: 0.8481 - val_acc: 0.6851\n",
      "Epoch 14/100\n",
      "12585/12585 [==============================] - 17s 1ms/sample - loss: 0.3135 - acc: 0.8664 - val_loss: 0.9883 - val_acc: 0.6273\n",
      "Epoch 15/100\n",
      "12585/12585 [==============================] - 17s 1ms/sample - loss: 0.3034 - acc: 0.8724 - val_loss: 0.9195 - val_acc: 0.6873\n",
      "Epoch 16/100\n",
      "12585/12585 [==============================] - 14s 1ms/sample - loss: 0.2945 - acc: 0.8774 - val_loss: 0.9217 - val_acc: 0.6841\n",
      "Epoch 17/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.2887 - acc: 0.8786 - val_loss: 0.6714 - val_acc: 0.7772\n",
      "Epoch 18/100\n",
      "12585/12585 [==============================] - 15s 1ms/sample - loss: 0.2789 - acc: 0.8827 - val_loss: 0.8295 - val_acc: 0.7245\n",
      "Epoch 19/100\n",
      "12585/12585 [==============================] - 15s 1ms/sample - loss: 0.2706 - acc: 0.8903 - val_loss: 0.7561 - val_acc: 0.7566\n",
      "Epoch 20/100\n",
      "12585/12585 [==============================] - 17s 1ms/sample - loss: 0.2637 - acc: 0.8910 - val_loss: 1.1561 - val_acc: 0.6196\n",
      "Epoch 21/100\n",
      "12585/12585 [==============================] - 17s 1ms/sample - loss: 0.2517 - acc: 0.8985 - val_loss: 0.9948 - val_acc: 0.6899\n",
      "Epoch 22/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.2462 - acc: 0.9003 - val_loss: 0.8382 - val_acc: 0.7464\n",
      "Epoch 23/100\n",
      "12585/12585 [==============================] - 15s 1ms/sample - loss: 0.2382 - acc: 0.9043 - val_loss: 1.0406 - val_acc: 0.6997\n",
      "Epoch 24/100\n",
      "12585/12585 [==============================] - 16s 1ms/sample - loss: 0.2295 - acc: 0.9095 - val_loss: 1.1910 - val_acc: 0.6756\n",
      "Epoch 25/100\n",
      " 3104/12585 [======>.......................] - ETA: 10s - loss: 0.2243 - acc: 0.9108"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, batch_size=16, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
